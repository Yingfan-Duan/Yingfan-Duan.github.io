---
layout:     post
title:      "Machine Learning: 知识点汇总"
subtitle:   "面试各类问题知识点整理"
date:       2022-5-4 17:00:00
author:     "Yingfan"
catalog: false
header-style: text
mathjax: true
tags:
  - machine learning
  - study notes
  - interview
---

# 1 基本概念

## 1.1 理解局部最优和全局最优

优化问题一般分为局部最优和全局最优。

（1）局部最优，就是在函数值空间的一个**有限区域**内寻找最小值；而全局最优，是在函数值空间**整个区域**寻找最小值问题

（2）函数局部最小点是它的函数值小于或等于**附近点**的点，但是有可能大于较远距离的点

（3）全局最小点是那种它的函数值小于或等于**所有的可行点**

## 1.2 各种常见算法

日常使用机器学习的任务中，我们经常会遇见各种算法：

- 回归算法
- 聚类算法
- 正则化方法
- 决策树学习
- 贝叶斯方法
- 基于核的算法
- 降维算法
- 集成算法
- 关联规则学习
- 人工神经网络，深度学习

# 2 机器学习学习方式

根据数据类型的不同，对一个问题的建模有不同的方式。依据不同的学习方式和输入数据，机器学习主要分为以下四种学习方式

## 2.1 监督学习

- 定义
  - 监督学习是使用已知正确答案的示例来训练模型。已知数据和其一一对应的标签，训练一个预测模型，将输入数据映射到标签的过程
- 应用场景
  - 分类问题
  - 回归问题
- 算法举例
  - SVM, NB, LR, KNN, DT, RF, AdaBoost, LDA
  - 深度学习(Deep Learning)也是大多数以监督学习的方式呈现

## 2.2 非监督式学习

- 定义
  - 在非监督式学习中，数据并不被特别标识，适用于具有数据集但无标签的情况。训练模型是为了推断出数据的一些内在结构。
- 应用场景
  - 关联规则学习，聚类
- 算法举例
  - Apriori, K-Means, DBSCAN

## 2.3 半监督式学习

- 定义
  - 在此学习方式下，输入数据部分被标记，部分没有被标记，这种学习模型可以用来进行预测。
- 应用场景
  - 应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测
- 算法举例
  - 图论推理算法（Graph Inference）
  - 拉普拉斯支持向量机（Laplacian SVM）

## 2.4 弱监督学习

- 定义
  - 弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素。 
  - 数据集的标签是不可靠的，这里的不可靠可以是标记不正确，多种标记，标记不充分，局部标记等。已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签。
- 算法举例
  - 给出一张包含气球的图片，需要得出气球在图片中的位置及气球和背景的分割线， 这就是已知弱标签学习强标签的问题。

# 3 分类算法

## 3.1 常用分类算法的优缺点

| 算法            | 优点 | 缺点 |
| --------------- | ---- | ---- |
| Bayes贝叶斯分类 |      |      |
| Decision Tree   |      |      |
| SVM             |      |      |
| KNN             |      |      |
| NN              |      |      |
| AdaBoost        |      |      |
|                 |      |      |

## 3.2 分类算法的评估方法

分类评估方法主要功能是用来评估分类算法的好坏，而评估一个分类器算法的好坏又包括许多项指 标。了解各种评估方法，在实际应用中选择正确的评估方法是十分重要的。

- **混淆矩阵**

  ![](/img/in-post/post-confusion-matrix.png)

- **评价指标**

  1. **正确率（accuracy）**  

     $accuracy = (TP+TN)/(P+N)$，正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好

  2. **错误率（error rate)**  

     描述被分类器错分的比例，对某一个实例来说，分对与分错是互斥事件，所以accuracy = 1 - error rate

  3. **召回率（recall）/ 灵敏度（sensitivity）**

     sensitivity = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力

  4. **特异性（specificity)**  

     specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。

  5. **精度（precision）**  

     precision=TP/(TP+FP)，精度是精确性的度量，表示被分为正例的示例中实际为正例的比例。

  6. **F1-score**

     - $F1=\frac{2precision\times recall}{precision+recall}$
     - 为了综合**多个类别**的分类情况，经常采用的还有微平均F1（micro-averaging）和宏平均F1（macro-averaging ）两种指标
       - 宏平均F1与微平均F1是以两种不同的平均方式求的全局F1指标。
       - 宏平均F1的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局 指标。
       - 微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。
       - 宏平均F1平等对待每一个类别，所以它的值主要受到**稀有类别**的影响
       - 而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别 的影响比较大。

  7. **其他评价指标**

     - 计算速度：分类器训练和预测需要的时间； 

     - 鲁棒性：处理缺失值和异常值的能力； 

     - 可扩展性：处理大数据集的能力；

     - 可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子

- **ROC曲线和PR曲线**

  - 
